import requests
from bs4 import BeautifulSoup
import logging

# Config Logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def check_sensitive_headers(url):
    try:
        logger.info(f"Starting to check URL: {url}")
        
        # Send GET req to URL
        logger.info("Sending GET request to the URL...")
        response = requests.get(url)
        logger.info(f"Received response with status code: {response.status_code}")
        
        # List Of Sensitive Headers
        sensitive_headers = [
            "x-powered-by",  # Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ ÙØ±ÛŒÙ…â€ŒÙˆØ±Ú© ÛŒØ§ Ø²Ø¨Ø§Ù† Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ
            "server",        # Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ø³Ø±ÙˆØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡ (Ù…Ø«Ù„ Apache, Nginx)
            "x-aspnet-version",  # Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ù†Ø³Ø®Ù‡ ASP.NET
            "x-runtime",     # Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ruby on Rails
            "x-library",     # Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Øµ
            "x-framework",   # Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ ÙØ±ÛŒÙ…â€ŒÙˆØ±Ú©â€ŒÙ‡Ø§
            "x-generator",   # Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ø³Ø§Ø®Øª (Ù…Ø«Ù„ WordPress)
            "via",           # Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§
            "x-cache",       # Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ú©Ø´
            "x-cdn",         # Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ CDN Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡
        ]
        
        # Check Req Headers
        logger.info("Checking Request Headers...")
        for header, value in response.request.headers.items():
            logger.info(f"Request Header: {header} = {value}")
            if any(sensitive in header.lower() for sensitive in sensitive_headers):
                logger.warning(f"ğŸš¨ Sensitive header found in Request: {header} = {value}")
        
        # Check Res Headers
        logger.info("Checking Response Headers...")
        for header, value in response.headers.items():
            logger.info(f"Response Header: {header} = {value}")
            if any(sensitive in header.lower() for sensitive in sensitive_headers):
                logger.warning(f"ğŸš¨ Sensitive header found in Response: {header} = {value}")
        
        # Check HTML
        logger.info("Parsing HTML content to find script and link tags...")
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # Check <script> Tags
        logger.info("Checking script tags...")
        for script in soup.find_all('script'):
            if script.src:  # Ø§Ú¯Ø± ÙØ§ÛŒÙ„ Ø®Ø§Ø±Ø¬ÛŒ Ø¨Ø§Ø´Ø¯
                script_url = script.src if script.src.startswith('http') else url + script.src
                logger.info(f"Found script: {script_url}")
                try:
                    logger.info(f"Fetching script content from: {script_url}")
                    script_response = requests.get(script_url)
                    if "version" in script_response.text.lower():
                        logger.warning(f"âš ï¸ Possible library version found in script: {script_url}")
                except requests.exceptions.RequestException as e:
                    logger.error(f"Failed to fetch script: {script_url} - {e}")
        
        # Check CSS for CDN
        logger.info("Checking CSS link tags...")
        for link in soup.find_all('link', rel='stylesheet'):
            if link.href:  # Ø§Ú¯Ø± ÙØ§ÛŒÙ„ Ø®Ø§Ø±Ø¬ÛŒ Ø¨Ø§Ø´Ø¯
                css_url = link.href if link.href.startswith('http') else url + link.href
                logger.info(f"Found CSS: {css_url}")
                try:
                    logger.info(f"Fetching CSS content from: {css_url}")
                    css_response = requests.get(css_url)
                    if "version" in css_response.text.lower():
                        logger.warning(f"âš ï¸ Possible library version found in CSS: {css_url}")
                except requests.exceptions.RequestException as e:
                    logger.error(f"Failed to fetch CSS: {css_url} - {e}")
        
        logger.info("Finished checking the URL.")
        
    except requests.exceptions.RequestException as e:
        logger.error(f"Error: {e}")

# URL HERE
url = "example.com"
check_sensitive_headers(url)
